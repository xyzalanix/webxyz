{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "(playground) audioWGAN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xyzalanix/webxyz/blob/main/(playground)_audioWGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDzK19g7jj_3"
      },
      "source": [
        "# audioWGAN\n",
        "\n",
        "```\n",
        "audioWGAN is an implementation of WGAN-GP using audio data.\n",
        "You can train it on any set of wav files. It generates one second audio samples throughout the training loop.\n",
        "\n",
        "Tips:\n",
        "- Avoid \"silence\" in your audio files. This will cause distracting noise.\n",
        "- Mess with sample generation intervals depending on your purpose.\n",
        "- ...\n",
        "\n",
        "Possibilities:\n",
        "- Longer audio samples!!!!!\n",
        "- Post-training generation with specific seeds.\n",
        "\n",
        "Credits:\n",
        "Harry Stuart: Original implementation and adaptation from WGAN-GP.\n",
        "Alan Ixba: Bit rate improvements, Usability, Notebook adaptation.\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9b1AioWuHyO",
        "cellView": "form"
      },
      "source": [
        "#@title # Install libraries\n",
        "!pip install scikit-image tqdm tensorflow-gpu==2.2\n",
        "!pip install tensorflow-addons==0.10.0\n",
        "!pip install tensorflow==2.1.0\n",
        "!pip install librosa==0.7.0 numba==0.48\n",
        "!pip install psutil\n",
        "!sudo -H pip install --upgrade youtube-dl\n",
        "\n",
        "!gdown --id 12DAbFvZ1-r83EiSjWiCzDQueg4zz_b--"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFX03Mmq80Sj",
        "cellView": "form"
      },
      "source": [
        "#@title # Let's get our data from youtube, start with a short duration (+/-5 min of audio).\n",
        "#@markdown Paste a url\n",
        "url = 'https://www.youtube.com/watch?v=kA-tyY2c6jQ' #@param {type:\"string\"}\n",
        "#@markdown Name your dataset\n",
        "name = 'grumax' #@param {type:\"string\"}\n",
        "!youtube-dl --audio-format mp4 $url -o $name\n",
        "!mkdir $name\n",
        "!ffmpeg -i '$name'.mkv ./$name/'$name'.wav\n",
        "!rm '$name'.mkv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVoCNvPpKsif"
      },
      "source": [
        "### Now we're ready to train.\n",
        "Expect several hours until you get decent results (depending on your dataset length)\n",
        "\n",
        "While training, you can start peeking generated files at ./results folder in the file explorer (left sidebar)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idM3jtqayF1L",
        "cellView": "form"
      },
      "source": [
        "#@title # Train\n",
        "# Import modules\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "import numpy as np\n",
        "import librosa\n",
        "import argparse\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import soundfile as sf\n",
        "\n",
        "# import GANModels\n",
        "import GANModels\n",
        "# Setup GPU settings\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "\n",
        "# Define hyperparameters\n",
        "\n",
        "#@markdown Point to the folder with wav file(s) we just downloaded\n",
        "DATA_DIR = 'grumax' #@param {type:\"string\"}\n",
        "#@markdown Name your model\n",
        "MODEL_NAME = 'grumax' #@param {type:\"string\"}\n",
        "MODEL_DIMS = 64 ###128 works, no sé qué cambia.\n",
        "NUM_SAMPLES = 16384\n",
        "D_UPDATES_PER_G_UPDATE = 5\n",
        "GRADIENT_PENALTY_WEIGHT = 10.0\n",
        "NOISE_LEN = 100\n",
        "EPOCHS = 10000\n",
        "#@markdown Choose how often to generate samples\n",
        "EPOCHS_PER_SAMPLE =  8#@param\n",
        "BATCH_SIZE = 16\n",
        "Fs = 44100\n",
        "\n",
        "\n",
        "\n",
        "print(\"Creating necessary directories\")\n",
        "\n",
        "paths = [\"logs/train\",\n",
        "         f\"models/{MODEL_NAME}/js\",\n",
        "         f\"results/{MODEL_NAME}\",]\n",
        "\n",
        "for path in paths:\n",
        "    if not os.path.exists(os.path.join(os.getcwd(), path)):\n",
        "        os.makedirs(path)\n",
        "\n",
        "# Define class that contains GAN infrastructure\n",
        "class GAN:\n",
        "    def __init__(self, model_dims=MODEL_DIMS, num_samples=NUM_SAMPLES,\n",
        "                 gradient_penalty_weight=GRADIENT_PENALTY_WEIGHT, instrument=MODEL_NAME,\n",
        "                 noise_len=NOISE_LEN, batch_size=BATCH_SIZE, sr=Fs):\n",
        "        self.model_dims = model_dims\n",
        "        self.num_samples = num_samples\n",
        "        self.noise_dims = (noise_len,)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.G = GANModels.Generator(self.model_dims, num_samples)\n",
        "        print(self.G.summary())\n",
        "\n",
        "        self.D = GANModels.Critic(self.model_dims, num_samples)\n",
        "        print(self.D.summary())\n",
        "\n",
        "        self.G_optimizer = Adam(learning_rate=1e-3, beta_1=0.5, beta_2=0.9)\n",
        "        self.D_optimizer = Adam(learning_rate=1e-4, beta_1=0.5, beta_2=0.9)\n",
        "\n",
        "        self.gradient_penalty_weight = gradient_penalty_weight\n",
        "\n",
        "        self.sr = sr\n",
        "\n",
        "        self.instrument = MODEL_NAME\n",
        "\n",
        "    # Loss function for critic\n",
        "    def _d_loss_fn(self, r_logit, f_logit):\n",
        "        r_loss = - tf.reduce_mean(r_logit)\n",
        "        f_loss = tf.reduce_mean(f_logit)\n",
        "        return r_loss, f_loss\n",
        "\n",
        "    # Loss function for generator\n",
        "    def _g_loss_fn(self, f_logit):\n",
        "        f_loss = - tf.reduce_mean(f_logit)\n",
        "        return f_loss\n",
        "\n",
        "    # Calculates gradient penalty\n",
        "    def _gradient_penalty(self, real, fake):\n",
        "        def _interpolate(a, b):\n",
        "            shape = [tf.shape(a)[0]] + [1] * (a.shape.ndims - 1)\n",
        "            alpha = tf.random.uniform(shape=shape, minval=0., maxval=1.)\n",
        "            inter = a + alpha * (b - a)\n",
        "            inter.set_shape(a.shape)\n",
        "            return inter\n",
        "\n",
        "        x = _interpolate(real, fake)\n",
        "        with tf.GradientTape() as t:\n",
        "            t.watch(x)\n",
        "            pred = self.D(x, training=True)\n",
        "\n",
        "        grad = t.gradient(pred, x)\n",
        "        norm = tf.norm(tf.reshape(grad, [tf.shape(grad)[0], -1]), axis=1)\n",
        "        gp = tf.reduce_mean((norm - 1.)**2)\n",
        "\n",
        "        return gp\n",
        "\n",
        "    # Trains generator by keeping critic constant\n",
        "    @tf.function\n",
        "    def train_G(self):\n",
        "        with tf.GradientTape() as t:\n",
        "            z = tf.random.normal(shape=(self.batch_size,) + self.noise_dims)\n",
        "            x_fake = self.G(z, training=True)\n",
        "            x_fake_d_logit = self.D(x_fake, training=True)\n",
        "            G_loss = self._g_loss_fn(x_fake_d_logit)\n",
        "\n",
        "        G_grad = t.gradient(G_loss, self.G.trainable_variables)\n",
        "        self.G_optimizer.apply_gradients(zip(G_grad, self.G.trainable_variables))\n",
        "\n",
        "        return {'g_loss': G_loss}\n",
        "\n",
        "    # Trains critic by keeping generator constant\n",
        "    @tf.function\n",
        "    def train_D(self, x_real):\n",
        "        with tf.GradientTape() as t:\n",
        "            z = tf.random.normal(shape=(x_real.shape[0],) + self.noise_dims)\n",
        "            x_fake = self.G(z, training=True)\n",
        "\n",
        "            x_real_d_logit = self.D(x_real, training=True)\n",
        "            x_fake_d_logit = self.D(x_fake, training=True)\n",
        "\n",
        "            x_real_d_loss, x_fake_d_loss = self._d_loss_fn(x_real_d_logit, x_fake_d_logit)\n",
        "            gp = self._gradient_penalty(x_real, x_fake)\n",
        "\n",
        "            D_loss = (x_real_d_loss + x_fake_d_loss) + gp * self.gradient_penalty_weight\n",
        "\n",
        "        D_grad = t.gradient(D_loss, self.D.trainable_variables)\n",
        "        self.D_optimizer.apply_gradients(zip(D_grad, self.D.trainable_variables))\n",
        "\n",
        "        return {'d_loss': x_real_d_loss + x_fake_d_loss, 'gp': gp}\n",
        "\n",
        "    # Creates music samples and saves current generator model\n",
        "    def sample(self, epoch, num_samples=4):        ######aquí num_samples es cuántos outputs por epoch output\n",
        "\n",
        "# ? ? ? saves the weights but not the model?  https://stackoverflow.com/questions/47266383/save-and-load-weights-in-keras\n",
        "        self.G.save(f\"models/{MODEL_NAME}/{epoch}.h5\")\n",
        "        self.G.save(f\"models/{MODEL_NAME}/js/{epoch}.json\")\n",
        "        z = tf.random.normal(shape=(num_samples,) + self.noise_dims)\n",
        "        result = self.G(z, training=False)\n",
        "        for i in range(num_samples):\n",
        "            audio = result[i, :, :]\n",
        "            audio = np.reshape(audio, (self.num_samples,))\n",
        "            librosa.output.write_wav(f\"results/{self.instrument}/{epoch}-{i}.wav\",\n",
        "                                     audio, sr=self.sr)\n",
        "\n",
        "\n",
        "###############################################################################################\n",
        "\n",
        "# Instantiate model\n",
        "gan = GAN()\n",
        "\n",
        "# Create training data\n",
        "X_train = []\n",
        "for file in os.listdir(DATA_DIR): ### Modify for your data directory\n",
        "    with open(DATA_DIR + fr\"/{file}\", \"rb\") as f:\n",
        "        samples, _ = librosa.load(f, Fs)\n",
        "        # Pad short audio files to NUM_SAMPLES duration\n",
        "        if len(samples) < NUM_SAMPLES:\n",
        "            audio = np.array([np.array([sample]) for sample in samples])\n",
        "            padding = np.zeros(shape=(NUM_SAMPLES - len(samples), 1), dtype='float32')\n",
        "            X_train.append(np.append(audio, padding, axis=0))\n",
        "        # Create slices of length NUM_SAMPLES from long audio\n",
        "        else:\n",
        "            p = len(samples) // (NUM_SAMPLES)\n",
        "            for i in range(p - 1):\n",
        "                sample = np.expand_dims(samples[i*NUM_SAMPLES:(i+1)*NUM_SAMPLES], axis=1)\n",
        "                X_train.append(sample)\n",
        "\n",
        "print(f\"X_train shape = {(len(X_train),) + X_train[0].shape}\")\n",
        "\n",
        "# Save some random training data slices and create baseline generated data for comparison\n",
        "for i in range(10):\n",
        "    librosa.output.write_wav(f\"results/{MODEL_NAME}/real-{i}.wav\",\n",
        "                             X_train[random.randint(0, len(X_train) - 1)], sr=Fs)\n",
        "\n",
        "gan.sample(\"fake\")\n",
        "\n",
        "train_summary_writer = tf.summary.create_file_writer(\"logs/train\")\n",
        "\n",
        "# Train GAN\n",
        "with train_summary_writer.as_default():\n",
        "    steps_per_epoch = len(X_train) // BATCH_SIZE\n",
        "\n",
        "    for e in range(EPOCHS):\n",
        "        for i in range(steps_per_epoch):\n",
        "            D_loss_sum = 0\n",
        "\n",
        "            # Update dcritic a set number of times for each update of the generator\n",
        "            for n in range(D_UPDATES_PER_G_UPDATE):\n",
        "                gan.D.reset_states()\n",
        "                D_loss_dict = gan.train_D(np.array(random.sample(X_train, BATCH_SIZE)))\n",
        "                D_loss_sum += D_loss_dict['d_loss']\n",
        "\n",
        "            # Calculate average loss of critic for current step\n",
        "            D_loss = D_loss_sum / D_UPDATES_PER_G_UPDATE\n",
        "\n",
        "            G_loss_dict = gan.train_G()\n",
        "            G_loss = G_loss_dict['g_loss']\n",
        "\n",
        "            # Write logs\n",
        "            tf.summary.scalar('d_loss', D_loss, step=(e*steps_per_epoch)+i)\n",
        "            tf.summary.scalar('g_loss', G_loss, step=(e*steps_per_epoch)+i)\n",
        "\n",
        "            print(f\"step {(e*steps_per_epoch)+i}: d_loss = {D_loss} g_loss = {G_loss}\")\n",
        "\n",
        "        # Periodically sample generator\n",
        "        if e % EPOCHS_PER_SAMPLE == 0:\n",
        "            gan.sample(e)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHDDlg6rJvgL",
        "cellView": "form"
      },
      "source": [
        "#@title # Finally, make a single audio clip from your (sorted) outputs\n",
        "#remove unnecessary clips\n",
        "!rm ./results/$name/fake-*.wav\n",
        "!rm ./results/$name/real-*.wav\n",
        "\n",
        "# order by date created\n",
        "!find ./results/$name/*.wav -printf \"file %Tc %p\\n\" | sort -n > clips-list.txt\n",
        "\n",
        "# remove date, leave filename\n",
        "f = open(\"clips-list.txt\", \"r\")\n",
        "g = open(\"clips-list-sort.txt\", \"w\")\n",
        "\n",
        "for line in f:\n",
        "    if line.strip():\n",
        "        g.write(\"\\'\"+\"\\t\".join(line.split()[8:]) + \"\\'\\n\")\n",
        "\n",
        "f.close()\n",
        "g.close()\n",
        "\n",
        "#reformat for ffmpeg\n",
        "filepath = \"clips-list-sort.txt\"\n",
        "with open(filepath) as fp:\n",
        "    lines = fp.read().splitlines()\n",
        "with open(filepath, \"w\") as fp:\n",
        "    for line in lines:\n",
        "        print(\"file \" + line, file=fp)\n",
        "\n",
        "#concatenate with ffmpeg into a single wav file\n",
        "!ffmpeg -f concat -safe 0 -i clips-list-sort.txt -c copy '$name'_full_progess.wav"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}